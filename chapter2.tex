\section{Konfidenzintervalle}

\subsection{Definition}

\begin{karte}{Konfidenzintervall}
Sei \(\abb{g}{\Theta}{\R}, x = (x_1, \ldots, x_n)\). Ein Intervall der Form \( [U(x), O(x)] \)
mit Funktionen \(\abb{U, O}{\mathfrak{X}}{\R}, U(x) \leq O(x)\) heißt Konfidenzintervall oder Vertrauensintervall 
für \(g(\vartheta)\). 

Sei \( \alpha \in (0,1) \) gegeben. Gilt 
\[ P_\vartheta(U(X) \leq g(\vartheta) \leq O(X)) \geq 1-\alpha \text{ für jedes } \vartheta \in \Theta, \]
so heißt \([U,O]\) Konfidenzintervall für \(g(\vartheta)\) zum Niveau \(1-\alpha\). 
Die Zahl 
\[ \inf_{\vartheta \in \Theta} P_\vartheta(U(X) \leq g(\vartheta) \leq O(X)) \]
heißt effektives Konfidenzniveau.

Für jedes \(n\) gelte für \(U_n = U_n(x^{(n)})\) und \(O_n = O_n(x^{(n)})\) die Ungleichung 
\[ U_n(x^{(n)}) \leq O_n(x^{(n)}) \forall x^{(n)}, \]
wobei \(x^{(n)} = (x_1, \ldots, x_n)\) ist. Weiter sei \(\alpha \in (0,1)\) gegeben. Gilt 
\[ \limes{n} P_\vartheta\left( U_n(X^{(n)}) \leq g(\vartheta) \leq O_n(X^{(n)}) \right) = 1-\alpha \forall \vartheta \in \Theta, \]
so heißt \([U_n, O_n]\) asymptotisches oder approximatives Konfidenzintervall für \(g(\vartheta)\) zum Niveau \(1-\alpha\).
\end{karte}

\begin{karte}{Konstruktionsprinzip}
Finde Zufallsvariable \(Z = f(X; \vartheta)\) (sog. Pivot), deren Verteilung nicht mehr von \(\vartheta\) abhängt. \\
Bestimme \(l,u\) so, dass \(P(l\leq Z \leq u) = 1-\alpha\).\\
Löse die Ungleichung nach \(g(\vartheta)\) auf.
\end{karte}

\begin{karte}{Gamma-Verteilung}
    \(X \sim \Gamma(\alpha, \beta)\) mit Dichte 
    \[ f(x) = \frac{\beta^\alpha}{\Gamma(\alpha)} e^{-\beta x} x^{\alpha - 1} \mathds{1}_{(0,\infty)}(x). \]
    
    Es gilt \(E X^r = \frac{\Gamma(\alpha + r)}{\beta^r \Gamma(\alpha)}\) für \(r > -\alpha\), sonst \(\infty\).
    
    \(E X = \frac{\alpha}{\beta}, V(X) = \frac{\alpha}{\beta^2}\).

    Ist \(X \sim \Gamma(\alpha, \beta)\) und \(c>0\), so gilt \(c\cdot X \sim \Gamma(\alpha, \frac{\beta}{c})\).
    
    Sind \(X\) und \(Y\) unabhängig, \(X \sim \Gamma(\alpha_1, \beta)\) und \(Y \sim \Gamma(\alpha_2, \beta)\), dann gilt 
    \[ X + Y \sim \Gamma(\alpha_1 + \alpha_2, \beta). \]

    Die \(\Gamma(1, \beta)\)-Verteilung ist die Exponentialverteilung mit Parameter \(\beta\).

    Gamma-Funktion: \(\Gamma(t) = \int_0^\infty e^{-x} x^{t-1} dx \ (t>0)\). 

    \(\Gamma(t+1) = t\Gamma(t)\),
    \(\Gamma(n+1) = n!\),
    \(\Gamma(\frac{1}{2}) = \sqrt{\pi}\).
\end{karte}

\begin{karte}{\(\chi^2\)-Verteilung}
Sei \(N_1, \ldots, N_k \oversett{u.i.v.}{\sim} \mathcal{N}(0,1)\). Die Verteilung von 
\[ Y := N_1^2 + \cdots + N_k^2 \]
heißt \textit{Chi-Quadrat-Verteilung mit \(k\) Freiheitsgraden} (\(Y \sim \chi_k^2\)).
\(Y\) besitzt die Dichte 
\[ f(y) = \frac{1}{2^{k/2} \Gamma(k/2)} e^{-y/2} y^{k/2-1}, y>0. \]
Weiter gilt: 
\[ E Y^r = \begin{cases}
    \frac{2^r \Gamma(r+\frac{k}{2})}{\Gamma(\frac{k}{2})}, &r > - \frac{k}{2}, \\
    \infty, & r \leq -\frac{k}{2}.
\end{cases} \]
Insbesondere gilt also \(E Y = k, V(Y) = 2k\).
\end{karte}

\begin{karte}{\(t\)-Verteilung}
Seien \(N,X\) unabhängig, \(N \sim \mathcal{N}(0,1), X \sim \chi_k^2\).\\
Die Verteilung von 
\[ Y := \frac{N}{\sqrt{\frac{X}{k}}} \]
heißt \textit{Student`sche \(t\)-Verteilung mit \(k\) Freiheitsgraden} (\(Y \sim t_k\)).

\(Y\) besitzt die Dichte 
\[ f(y) = \frac{1}{\sqrt{\pi k}} \frac{\Gamma(\frac{k+1}{2})}{\Gamma(\frac{k}{2})} (1 + \frac{y^2}{k})^{-\frac{k+1}{2}}, y \in \R. \]
Weiter gilt: 
\[ E Y = 0, k \geq 2, V(Y) = \frac{k}{k-2}, k \geq 3. \]
\end{karte}

\begin{karte}{\(F\)-Verteilung}
Seien \(R, S\) unabhängig, \(R \sim \chi_r^2, S \sim \chi_s^2\). Die Verteilung von 
\[ Y := \frac{\frac{1}{r} R}{\frac{1}{s} S} \]
heißt \textit{F(ischer)-Verteilung mit \(r\) Zähler- und \(s\) Nenner-Freiheitsgraden} (\(Y \sim F_{r,s}\)).

\(Y\) besitzt die Dichte 
\[ EY = \frac{s}{s-2}, s > 2, V(Y) = \frac{2s^2(r+s-2)}{r(s-2)^2(s-4)}, s > 4.\]
\end{karte}

\begin{karte}{Momenterzeugende Funktion}
Sei \(X\) eine ZV mit \(E|e^{tX}| < \infty\) für \(-h < t < h\) für ein \(h > 0\). 
Dann heißt 
\[ M(t) = E(e^{tX}), -h < t < h, \]
\textit{momenterzeugende Funktion (MEF)} von \(X\).
Es gilt: 
\begin{enumerate}
    \item \(M(t)\) ist beliebig oft differenzierbar für \(t \in (-h, h)\), und es gilt 
    \[ M^{(k)}(0) = E X^k, k = 1,\ldots \]
    \item Sind \(X\) und \(Y\) Zufallsvariablen mit momenterzeugenden Funktionen \(M_X(t)\) 
    und \(M_Y(t)\) für \(t \in (-h,h)\), dann gilt: 
    \[ F_X(z) = F_y(z) \forall z\in \R \Leftrightarrow M_X(t) = M_Y(t) \forall t\in (-h, h). \]
    \item Sind \(X,Y\) unabhängig mit momenterzeugenden Funktionen \(M_X(t)\) und \(M_Y(t)\) für \(t\in (-h,h)\),
    so gilt 
    \[ M_{X+Y}(t) = M_X(t) \cdot M_Y(t) \forall t\in (-h,h). \]
\end{enumerate}
\end{karte}

\subsection{Satz von Student}

\begin{karte}{Der Satz von Student}
Es seien \(X_1, \ldots, X_n \oversett{u.i.v.}{\sim} \mathcal{N}(\mu, \sigma^2), n \geq 2\),
\[ \bar{X} = \frac{1}{n} \sum_{i=1}^n X_i, S^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - \bar{X})^2, S = +\sqrt{S^2}. \]
Dann gilt 
\begin{enumerate}
    \item \(\bar{X} \sim \mathcal{N}(\mu, \frac{\sigma^2}{n})\).
    \item \(\bar{X}\) und \(S^2\) sind unabhängig.
    \item \(\frac{(n-1)S^2}{\sigma^2} = \frac{1}{\sigma^2} \sum_{i=1}^n (X_i - \bar{X})^2 \sim \chi_{n-1}^2. \)
    \item \(T = \frac{\sqrt{n}(\bar{X} - \mu)}{S} \sim t_{n-1}\).
\end{enumerate}
\end{karte}

\subsection{Konf.intervalle bei \(\mathcal{N}(\mu, \sigma^2)\)}

\begin{karte}{Konfidenzintervall für \(\mu\)}
Sei \(X_1, \ldots, X_n \oversett{u.i.v.}{\mathcal{N}(\mu, \sigma^2)}, \vartheta = (\mu, \sigma^2) \) unbekannt.
Wegen \(\frac{\sqrt{n}(\bar{X}-\mu)}{S} \sim t_{n-1}\) gilt 
\[ P_\vartheta\left( \abs{\frac{\sqrt{n}(\bar{X}-\mu)}{S}} \leq t_{n-1;1-\frac{\alpha}{2}} = 1-\alpha \right), \]
wobei \(t_{n-1;p}\) das \(p\)-Quantil von \(t_{n-1}\) bezeichnet.

Das Intervall 
\[ [\bar{X} - \frac{S}{\sqrt{n}} t_{n-1;1-\frac{\alpha}{2}}, \bar{X} + \frac{S}{\sqrt{n}} t_{n-1;1-\frac{\alpha}{2}} ] \]
ist also ein Konfidenzintervall für \(\mu\) zur Vertrauenswahrscheinlichkeit \(1-\alpha\).
\end{karte}

\begin{karte}{Konfidenzintervalle für \(\sigma^2\) und \(\sigma\)}
Wegen \( \frac{(n-1)S^2}{\sigma^2} \sim \chi_{n-1}^2 \) gilt 
\[ P_\vartheta\left( \chi_{n-1;\frac{\alpha}{2}}^2 \leq \frac{(n-1)S^2}{\sigma^2} \leq \chi_{n-1;1-\frac{\alpha}{2}}^2 \right) = 1-\alpha. \]

Äquivalent: 
\[ P_\vartheta \left( 
    \underbrace{\frac{(n-1)S^2}{\chi_{n-1;1-\frac{\alpha}{2}}}}_{=: U} 
    \leq \sigma^2 \leq 
    \underbrace{\frac{(n-1)S^2}{\chi_{n-1;\frac{\alpha}{2}}}}_{=: O} \right) 
    = 1-\alpha \]
Somit gilt: 
\begin{itemize}
    \item \([U,O]\) ist ein Konfidenzintervall für \(\sigma^2\) zum Niveau \(1-\alpha\),
    \item \([\sqrt{U}, \sqrt{O}]\) ist ein Konfidenzintervall für \(\sigma\) zum Niveau \(1-\alpha\).
\end{itemize}
\end{karte}

\begin{karte}{Einseitige Konfidenzintervalle für \(\mu\) und \(\sigma^2\)}
\[ \left[ \bar{X} - \frac{S}{\sqrt{n}} \cdot t_{n-1; 1-\alpha}, \infty \right) \text{ bzw. } \left(-\infty, \bar{X} + \frac{S}{\sqrt{n} \cdot t_{n-1;1-\alpha}} \right] \]
sind Konfidenzintervalle für \(\mu\) mit Überdeckungswahrscheinlichkeit \(1-\alpha\).

\[ \left( 0, \frac{(n-1)S^2}{\chi_{n-1;\alpha}^2} \right] \text{ bzw. } \left[ \frac{(n-1)S^2}{\chi_{n-1;1-\alpha}^2}, \infty \right) \]
sind Konfidenzintervalle zur Konfidenzwahrscheinlichkeit \(1-\alpha\) für \(\sigma^2\).
\end{karte}